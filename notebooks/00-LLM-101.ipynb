{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84b7df5c-f989-4d2c-9bfb-1c381c1d045a",
   "metadata": {},
   "source": [
    "# LLM 101\n",
    "\n",
    "## Abstract (generated from Perplexity)\n",
    "\n",
    "Large Language Models (LLMs) are deep learning models designed to process and understand vast amounts of natural language data. They are built on neural network architectures, particularly the transformer architecture, which allows them to capture complex language patterns and relationships between words or phrases in large-scale text datasets. \n",
    "\n",
    "\n",
    "Key blogs on LLMs:\n",
    "- To get basic understanding of GPT or LLM in general : https://jalammar.github.io/illustrated-gpt2/\n",
    "- Google colab for training LLMs with BnB: https://colab.research.google.com/drive/1VoYNfYDKcKRQRor98Zbf2-9VQTtGJ24k?usp=sharing#scrollTo=jq0nX33BmfaC\n",
    "\n",
    "\n",
    "\n",
    "Common NLP tasks: \n",
    "- **classify whole sentences**: determine if the sentence is grammatically correct or not, if the two sentences are logically related\n",
    "- **classify each word in a sentence**: identify grammatical components of a sentence\n",
    "- **generate text content**: completing a prompt with auto-generated text\n",
    "- **extract answer from a text** : given a qn and a context, extract answer to the question\n",
    "- **generate new sentence from an input text**: translate text to another language or summarize a text   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f1f7c1-19a0-407d-adcc-2b680608ec05",
   "metadata": {},
   "source": [
    "## Working with Transformers \n",
    "\n",
    "from : https://huggingface.co/learn/nlp-course/chapter1/3?fw=pt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f8a110-22e8-434c-9d32-534693f62346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b9d5e90-0708-43d1-89ae-e938797d3e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e617b8a0-776c-4d01-ae8b-5a9e54c64645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997451901435852}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('India is winning the world cup 2023')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6767a1-9c5d-4932-a40b-29c1ac33103a",
   "metadata": {},
   "source": [
    "There are 3 steps for the model :\n",
    "1. text is first pre-processed into a format the model can understand\n",
    "2. pre-processed inputs are passed to the model\n",
    "3. predictions of the model are post-processed in natural english "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a785e-04a7-448b-bcab-b19ee0a69de2",
   "metadata": {},
   "source": [
    "### Zero shot Text classification\n",
    "\n",
    "In this a set of labels are passed to pipeline alongwith input sentence and the model will classify the sentence into one of the labels without having to tune the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fe0c352-2219-460a-82db-fa2970c6d51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████████████████████████| 1.15k/1.15k [00:00<00:00, 158kB/s]\n",
      "Downloading model.safetensors: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1.63G/1.63G [00:39<00:00, 41.7MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████| 26.0/26.0 [00:00<00:00, 6.77kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|█████████████████████████████████████████████████████████████████████████████████████| 899k/899k [00:00<00:00, 1.15MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████████████████████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 893kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|███████████████████████████████████████████████████████████████████████████████████| 1.36M/1.36M [00:00<00:00, 1.46MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'India is winning the world cup 2023',\n",
       " 'labels': ['sports', 'politics', 'education'],\n",
       " 'scores': [0.986595630645752, 0.008057733997702599, 0.00534663675352931]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline('zero-shot-classification')\n",
    "classifier(\n",
    "    \"India is winning the world cup 2023\",\n",
    "    candidate_labels=['education', 'sports', 'politics']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec22c42a-6a0a-41d8-a8d2-935597def327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'India is winning the world cup 2023',\n",
       " 'labels': ['sports', 'positive', 'negative', 'politics', 'education'],\n",
       " 'scores': [0.62184077501297,\n",
       "  0.36308449506759644,\n",
       "  0.006626029033213854,\n",
       "  0.005078704562038183,\n",
       "  0.0033699285704642534]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what happens when sentiment is also added\n",
    "classifier(\n",
    "    \"India is winning the world cup 2023\",\n",
    "    candidate_labels=['education', 'sports', 'politics', 'positive', 'negative']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad434b1-8cdc-490a-9acf-718cfe1b575d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
